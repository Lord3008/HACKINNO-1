{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e588b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 150 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, text, sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "# Define tokenizer\n",
    "tokenizer = text.Tokenizer(num_words=10000)  # Adjust as needed\n",
    "\n",
    "# Custom Transformer Block\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Frequency Domain Analysis\n",
    "class FrequencyDomainSpectralAnalysis(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FrequencyDomainSpectralAnalysis, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        gray = tf.image.rgb_to_grayscale(inputs)\n",
    "        freq = tf.signal.fft2d(tf.cast(gray, tf.complex64))\n",
    "        freq_shifted = tf.signal.fftshift(freq)\n",
    "        magnitude = tf.abs(freq_shifted)\n",
    "        magnitude = tf.math.log1p(magnitude)\n",
    "        magnitude = tf.image.per_image_standardization(magnitude)\n",
    "        magnitude = tf.image.resize(magnitude, [inputs.shape[1], inputs.shape[2]])\n",
    "        return magnitude\n",
    "\n",
    "# Convolutional Transformer Encoder (CTE) Branch\n",
    "class ConvolutionalTransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_layers, num_heads, ff_dim):\n",
    "        super(ConvolutionalTransformerEncoder, self).__init__()\n",
    "        self.embedding = layers.Conv2D(embed_dim, kernel_size=3, strides=1, padding='same')\n",
    "        self.pooling = layers.GlobalAveragePooling2D()\n",
    "        self.transformer_layers = [\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.fc = layers.Dense(embed_dim)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pooling(x)\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            x = transformer_layer(x, training=training)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Language Transformer-Based Encoder\n",
    "class LanguageTransformerEncoder(layers.Layer):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads, ff_dim):\n",
    "        super(LanguageTransformerEncoder, self).__init__()\n",
    "        self.embedding = layers.Embedding(vocab_size, embed_dim)\n",
    "        self.transformer_layers = [\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.fc = layers.Dense(embed_dim)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.embedding(x)\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            x = transformer_layer(x, training=training)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Weighted Feature Embeddings Fusion\n",
    "class WeightedFeatureFusion(layers.Layer):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(WeightedFeatureFusion, self).__init__()\n",
    "        self.weight = self.add_weight(shape=(embed_dim,), initializer='ones', trainable=True)\n",
    "    \n",
    "    def call(self, feature1, feature2):\n",
    "        fused = feature1 * self.weight + feature2 * (1 - self.weight)\n",
    "        return fused\n",
    "\n",
    "# SVFT Decoder and Classification Head Layers\n",
    "class SVFTDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_classes):\n",
    "        super(SVFTDecoder, self).__init__()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "        #self.activation('sigmoid')\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.fc(x)\n",
    "        #x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class DeepfakeDetectionModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads, ff_dim, num_classes, **kwargs):\n",
    "        super(DeepfakeDetectionModel, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.image_model = ConvolutionalTransformerEncoder(embed_dim, num_layers, num_heads, ff_dim)\n",
    "        self.text_model = LanguageTransformerEncoder(vocab_size, embed_dim, num_layers, num_heads, ff_dim)\n",
    "        self.fusion = WeightedFeatureFusion(embed_dim)\n",
    "        self.decoder = SVFTDecoder(embed_dim, num_classes)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        images, texts = inputs\n",
    "        img_features = self.image_model(images, training=training)\n",
    "        text_features = self.text_model(texts, training=training)\n",
    "        fused_features = self.fusion(img_features, text_features)\n",
    "        output = self.decoder(fused_features, training=training)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DeepfakeDetectionModel, self).get_config()\n",
    "        config.update({\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"num_classes\": self.num_classes,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "# Training script\n",
    "if __name__ == \"__main__\":\n",
    "    def load_image_text_dataset(image_dir, metadata_file, batch_size=8, img_size=(224, 224), max_seq_length=50):\n",
    "        # Load images from directory\n",
    "        image_dataset = image_dataset_from_directory(\n",
    "            image_dir,\n",
    "            labels=None,\n",
    "            image_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False  # Shuffle will be handled later\n",
    "        )\n",
    "\n",
    "        # Load metadata from CSV file\n",
    "        metadata = pd.read_csv(metadata_file)\n",
    "\n",
    "        # Extract texts and labels from metadata\n",
    "        texts = metadata['Name'].tolist()\n",
    "        labels = metadata['Label'].tolist()\n",
    "\n",
    "        # Convert string labels to integers\n",
    "        label_mapping = {'Real': 0, 'Fake': 1}\n",
    "        int_labels = [label_mapping[label] for label in labels]\n",
    "\n",
    "        # Tokenize and pad text sequences\n",
    "        tokenizer.fit_on_texts(texts)\n",
    "        sequences = tokenizer.texts_to_sequences(texts)\n",
    "        text_tensor = pad_sequences(sequences, maxlen=max_seq_length)\n",
    "        label_tensor = tf.constant(int_labels)\n",
    "\n",
    "        # Create a dataset by zipping images, texts, and labels\n",
    "        # Ensure that image_dataset has the same order as metadata\n",
    "        image_iterator = image_dataset.as_numpy_iterator()\n",
    "        def gen():\n",
    "            for img_batch, label_batch in image_iterator:\n",
    "                # Assuming labels are not used from image_dataset\n",
    "                for img in img_batch:\n",
    "                    yield (img, text_tensor.pop(0)), label_tensor.numpy().tolist().pop(0)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_signature=(\n",
    "                (\n",
    "                    tf.TensorSpec(shape=(img_size[0], img_size[1], 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(max_seq_length,), dtype=tf.int32)\n",
    "                ),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "            )\n",
    "        )\n",
    "        dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    # Load dataset\n",
    "    image_directory = \"C:\\\\Users\\\\Lord Sen\\\\ML\\\\DeepFake_det\\\\FF++_Faces_224\\\\FF++_Faces_224\"  # Update as needed\n",
    "    metadata_file = \"C:\\\\Users\\\\Lord Sen\\\\ML\\\\metadata.csv\"  # Update as needed\n",
    "    train_dataset = load_image_text_dataset(image_directory, metadata_file)\n",
    "    \n",
    "    # Define model hyperparameters\n",
    "    vocab_size = 10000\n",
    "    embed_dim = 128\n",
    "    num_layers = 2\n",
    "    num_heads = 4\n",
    "    ff_dim = 256\n",
    "    num_classes = 2\n",
    "\n",
    "    # Initialize the model\n",
    "    model = DeepfakeDetectionModel(\n",
    "        vocab_size=vocab_size, \n",
    "        embed_dim=embed_dim, \n",
    "        num_layers=num_layers, \n",
    "        num_heads=num_heads, \n",
    "        ff_dim=ff_dim, \n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    # Build the model by passing a sample input\n",
    "    sample_images = tf.random.uniform((1, 224, 224, 3))\n",
    "    sample_texts = tf.random.uniform((1, 50), maxval=vocab_size, dtype=tf.int32)  # Fix: Specify maxval\n",
    "    model((sample_images, sample_texts), training=True)\n",
    "\n",
    "   # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    #model.fit(train_dataset, epochs=10)\n",
    "\n",
    "    # Save the model in the `.keras` format\n",
    "    model.save('deepfake_detection_model.keras')\n",
    "\n",
    "    # Define custom objects for loading the model\n",
    "    custom_objects = {\n",
    "       \"DeepfakeDetectionModel\": DeepfakeDetectionModel, \n",
    "       \"TransformerBlock\": TransformerBlock,\n",
    "       \"ConvolutionalTransformerEncoder\": ConvolutionalTransformerEncoder,\n",
    "       \"LanguageTransformerEncoder\": LanguageTransformerEncoder,\n",
    "       \"WeightedFeatureFusion\": WeightedFeatureFusion,\n",
    "       \"SVFTDecoder\": SVFTDecoder\n",
    "   }\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('deepfake_detection_model.keras', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68c6a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 150 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, text, sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "# Define tokenizer\n",
    "tokenizer = text.Tokenizer(num_words=10000)  # Adjust as needed\n",
    "\n",
    "# Custom Transformer Block\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Frequency Domain Analysis\n",
    "class FrequencyDomainSpectralAnalysis(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FrequencyDomainSpectralAnalysis, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        gray = tf.image.rgb_to_grayscale(inputs)\n",
    "        freq = tf.signal.fft2d(tf.cast(gray, tf.complex64))\n",
    "        freq_shifted = tf.signal.fftshift(freq)\n",
    "        magnitude = tf.abs(freq_shifted)\n",
    "        magnitude = tf.math.log1p(magnitude)\n",
    "        magnitude = tf.image.per_image_standardization(magnitude)\n",
    "        magnitude = tf.image.resize(magnitude, [inputs.shape[1], inputs.shape[2]])\n",
    "        return magnitude\n",
    "\n",
    "# Convolutional Transformer Encoder (CTE) Branch\n",
    "class ConvolutionalTransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_layers, num_heads, ff_dim):\n",
    "        super(ConvolutionalTransformerEncoder, self).__init__()\n",
    "        self.embedding = layers.Conv2D(embed_dim, kernel_size=3, strides=1, padding='same')\n",
    "        self.pooling = layers.GlobalAveragePooling2D()\n",
    "        self.transformer_layers = [\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.fc = layers.Dense(embed_dim)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pooling(x)\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            x = transformer_layer(x, training=training)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Language Transformer-Based Encoder\n",
    "class LanguageTransformerEncoder(layers.Layer):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads, ff_dim):\n",
    "        super(LanguageTransformerEncoder, self).__init__()\n",
    "        self.embedding = layers.Embedding(vocab_size, embed_dim)\n",
    "        self.transformer_layers = [\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.fc = layers.Dense(embed_dim)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.embedding(x)\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            x = transformer_layer(x, training=training)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Weighted Feature Embeddings Fusion\n",
    "class WeightedFeatureFusion(layers.Layer):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(WeightedFeatureFusion, self).__init__()\n",
    "        self.weight = self.add_weight(shape=(embed_dim,), initializer='ones', trainable=True)\n",
    "    \n",
    "    def call(self, feature1, feature2):\n",
    "        fused = feature1 * self.weight + feature2 * (1 - self.weight)\n",
    "        return fused\n",
    "\n",
    "class SVFTDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_classes):\n",
    "        super(SVFTDecoder, self).__init__()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "        # Change this if num_classes is 1 for binary classification\n",
    "        self.activation = layers.Activation('sigmoid') if num_classes == 1 else layers.Activation('softmax')\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class DeepfakeDetectionModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads, ff_dim, num_classes, **kwargs):\n",
    "        super(DeepfakeDetectionModel, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.image_model = ConvolutionalTransformerEncoder(embed_dim, num_layers, num_heads, ff_dim)\n",
    "        self.text_model = LanguageTransformerEncoder(vocab_size, embed_dim, num_layers, num_heads, ff_dim)\n",
    "        self.fusion = WeightedFeatureFusion(embed_dim)\n",
    "        self.decoder = SVFTDecoder(embed_dim, num_classes)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        images, texts = inputs\n",
    "        img_features = self.image_model(images, training=training)\n",
    "        text_features = self.text_model(texts, training=training)\n",
    "        fused_features = self.fusion(img_features, text_features)\n",
    "        output = self.decoder(fused_features, training=training)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DeepfakeDetectionModel, self).get_config()\n",
    "        config.update({\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"num_classes\": self.num_classes,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "# Training script\n",
    "if __name__ == \"__main__\":\n",
    "    def load_image_text_dataset(image_dir, metadata_file, batch_size=8, img_size=(224, 224), max_seq_length=50):\n",
    "        # Load images from directory\n",
    "        image_dataset = image_dataset_from_directory(\n",
    "            image_dir,\n",
    "            labels=None,\n",
    "            image_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False  # Shuffle will be handled later\n",
    "        )\n",
    "\n",
    "        # Load metadata from CSV file\n",
    "        metadata = pd.read_csv(metadata_file)\n",
    "\n",
    "        # Extract texts and labels from metadata\n",
    "        texts = metadata['Name'].tolist()\n",
    "        labels = metadata['Label'].tolist()\n",
    "\n",
    "        # Convert string labels to integers\n",
    "        label_mapping = {'Real': 0, 'Fake': 1}\n",
    "        int_labels = [label_mapping[label] for label in labels]\n",
    "\n",
    "        # Tokenize and pad text sequences\n",
    "        tokenizer.fit_on_texts(texts)\n",
    "        sequences = tokenizer.texts_to_sequences(texts)\n",
    "        text_tensor = pad_sequences(sequences, maxlen=max_seq_length)\n",
    "        label_tensor = tf.constant(int_labels)\n",
    "\n",
    "        # Create a dataset by zipping images, texts, and labels\n",
    "        # Ensure that image_dataset has the same order as metadata\n",
    "        image_iterator = image_dataset.as_numpy_iterator()\n",
    "        def gen():\n",
    "            for img_batch, _ in image_iterator:\n",
    "                for i in range(len(img_batch)):\n",
    "                    img = img_batch[i]\n",
    "                    text = text_tensor[i]\n",
    "                    label = label_tensor[i]\n",
    "                    yield (img, text), label\n",
    "\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_signature=(\n",
    "                (\n",
    "                    tf.TensorSpec(shape=(img_size[0], img_size[1], 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(max_seq_length,), dtype=tf.int32)\n",
    "                ),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "            )\n",
    "        )\n",
    "        dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    # Load dataset\n",
    "    image_directory = \"C:\\\\Users\\\\Lord Sen\\\\ML\\\\DeepFake_det\\\\FF++_Faces_224\\\\FF++_Faces_224\"  # Update as needed\n",
    "    metadata_file = \"C:\\\\Users\\\\Lord Sen\\\\ML\\\\metadata.csv\"  # Update as needed\n",
    "    train_dataset = load_image_text_dataset(image_directory, metadata_file)\n",
    "    \n",
    "    # Define model hyperparameters\n",
    "    vocab_size = 10000\n",
    "    embed_dim = 128\n",
    "    num_layers = 2\n",
    "    num_heads = 4\n",
    "    ff_dim = 256\n",
    "    num_classes = 1\n",
    "\n",
    "    # Initialize the model\n",
    "    model = DeepfakeDetectionModel(\n",
    "        vocab_size=vocab_size, \n",
    "        embed_dim=embed_dim, \n",
    "        num_layers=num_layers, \n",
    "        num_heads=num_heads, \n",
    "        ff_dim=ff_dim, \n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    # Build the model by passing a sample input\n",
    "    sample_images = tf.random.uniform((1, 224, 224, 3))\n",
    "    sample_texts = tf.random.uniform((1, 50), maxval=vocab_size, dtype=tf.int32)  # Fix: Specify maxval\n",
    "    model((sample_images, sample_texts), training=True)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    #model.fit(train_dataset, epochs=10)\n",
    "\n",
    "    # Save the model in the `.keras` format\n",
    "    model.save('deepfake_detection_model.keras')\n",
    "\n",
    "    # Define custom objects for loading the model\n",
    "    custom_objects = {\n",
    "       \"DeepfakeDetectionModel\": DeepfakeDetectionModel, \n",
    "       \"TransformerBlock\": TransformerBlock,\n",
    "       \"ConvolutionalTransformerEncoder\": ConvolutionalTransformerEncoder,\n",
    "       \"LanguageTransformerEncoder\": LanguageTransformerEncoder,\n",
    "       \"WeightedFeatureFusion\": WeightedFeatureFusion,\n",
    "       \"SVFTDecoder\": SVFTDecoder\n",
    "   }\n",
    "\n",
    "    # Load the model\n",
    "    loaded_model = tf.keras.models.load_model('deepfake_detection_model.keras', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef613ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.58494735  0.6527562 ]\n",
      " [-1.0875294   0.91202134]\n",
      " [ 0.1769378   1.0657979 ]\n",
      " [-0.23638088  1.3789895 ]\n",
      " [-0.2632763   0.55552715]\n",
      " [-0.10037638  0.5711725 ]\n",
      " [-0.8815618   1.5987645 ]\n",
      " [ 0.29555595  1.0402079 ]], shape=(8, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (8, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example input data\n",
    "images = tf.random.normal([8, 224, 224, 3])  # Batch of 8 images\n",
    "texts = tf.random.uniform([8, 50], maxval=vocab_size, dtype=tf.int32)  # Batch of 8 text sequences\n",
    "\n",
    "    # Forward pass\n",
    "outputs = model((images, texts))\n",
    "print(outputs)  # Should be [8, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede830c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 is classified as Fake\n",
      "Image 1 is classified as Real\n",
      "Image 2 is classified as Fake\n",
      "Image 3 is classified as Fake\n",
      "Image 4 is classified as Fake\n",
      "Image 5 is classified as Fake\n",
      "Image 6 is classified as Real\n",
      "Image 7 is classified as Real\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = DeepfakeDetectionModel(vocab_size=vocab_size, embed_dim=embed_dim, num_layers=num_layers, num_heads=num_heads, ff_dim=ff_dim, num_classes=num_classes)\n",
    "\n",
    "# Example input data\n",
    "images = tf.random.normal([8, 224, 224, 3])  # Batch of 8 images\n",
    "texts = tf.random.uniform([8, 50], maxval=vocab_size, dtype=tf.int32)  # Batch of 8 text sequences\n",
    "\n",
    "# Forward pass\n",
    "outputs = model((images, texts))\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = tf.nn.softmax(outputs, axis=1)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predictions = tf.argmax(probabilities, axis=1)\n",
    "\n",
    "# Convert predictions to numpy array for easier manipulation\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "# Print results\n",
    "for i, prediction in enumerate(predictions):\n",
    "    if prediction == 0:\n",
    "        print(f\"Image {i} is classified as Real\")\n",
    "    else:\n",
    "        print(f\"Image {i} is classified as Fake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9531dfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming the model class definitions are already provided as above\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((224, 224))\n",
    "    image = np.array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Function to classify the image\n",
    "def classify_image(image):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image)\n",
    "    \n",
    "    # Example text data (this should be adapted to your specific case)\n",
    "    vocab_size = 10000  # Example vocab size\n",
    "    texts = tf.random.uniform([1, 50], maxval=vocab_size, dtype=tf.int32)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model((image, texts))\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = tf.nn.softmax(outputs, axis=1)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    prediction = tf.argmax(probabilities, axis=1).numpy()[0]\n",
    "    \n",
    "    if prediction == 1:\n",
    "        return \"Real\"\n",
    "    else:\n",
    "        return \"Fake\"\n",
    "\n",
    "# Define the model parameters\n",
    "vocab_size = 10000\n",
    "embed_dim = 128\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "ff_dim = 256\n",
    "num_classes = 2\n",
    "\n",
    "# Initialize the model\n",
    "model = DeepfakeDetectionModel(vocab_size=vocab_size, embed_dim=embed_dim, num_layers=num_layers, num_heads=num_heads, ff_dim=ff_dim, num_classes=num_classes)\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Deepfake Detection_\",\n",
    "    description=\"Upload an image to check if it's real or fake.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da76d147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lord Sen\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming the model class definitions are already provided as above\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((224, 224))\n",
    "    image = np.array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Function to classify the image\n",
    "def classify_image(image):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image)\n",
    "    \n",
    "    # Example text data (this should be adapted to your specific case)\n",
    "    vocab_size = 10000  # Example vocab size\n",
    "    texts = tf.random.uniform([1, 50], maxval=vocab_size, dtype=tf.int32)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model((image, texts))\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = tf.nn.softmax(outputs, axis=1)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    prediction = tf.argmax(probabilities, axis=1).numpy()[0]\n",
    "    \n",
    "    if prediction == 0:\n",
    "        return \"Real\"\n",
    "    else:\n",
    "        return \"Fake\"\n",
    "\n",
    "# Define the model parameters\n",
    "vocab_size = 10000\n",
    "embed_dim = 128\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "ff_dim = 256\n",
    "num_classes = 2\n",
    "\n",
    "# Initialize the model\n",
    "model = DeepfakeDetectionModel(vocab_size=vocab_size, embed_dim=embed_dim, num_layers=num_layers, num_heads=num_heads, ff_dim=ff_dim, num_classes=num_classes)\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Deepfake Detection_\",\n",
    "    description=\"Upload an image to check if it's real or fake.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c78129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
